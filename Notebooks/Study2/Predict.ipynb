{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cdaeeecb90a074a8",
   "metadata": {},
   "source": [
    "# Predict\n",
    "Predict gaze on normalized images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c7f64ce932df3d",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59aee880-cf77-4309-97f4-e81d264d730b",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-22T17:47:58.306291800Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join('..', '..')))\n",
    "from Models import CNNResNetSWAttention\n",
    "from Utils.LoadingUtils import read_images_separate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784da7de879bc5bc",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a42e35d9c9616b7",
   "metadata": {},
   "source": [
    "### Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c264de27053e5d07",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-22T17:47:58.319801700Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "model_path = '../../Models/rn_sw_attention__tf_model'\n",
    "base_path = '../../Datasets/Study_2/Participants'\n",
    "data_directory = '../../Datasets/Study_2/Meta.tsv'\n",
    "normalised_directory = 'Normalised'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1480253014a5d31a",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "097c1604-18e7-4398-8768-c083d493dd2d",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-22T17:47:58.319801700Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_model(model_path, bn=True, first_dense_units=256, fc_layer_units=None, lr=None):\n",
    "    if fc_layer_units is None:\n",
    "        fc_layer_units = [256, 512]\n",
    "    if lr is None:\n",
    "        lr = [1e-5, 1e-4]\n",
    "\n",
    "    cnn_model = CNNResNetSWAttention.create_resnet18_sw__attention(input_shape=(60, 36, 1),\n",
    "                                                                   bn=bn,\n",
    "                                                                   first_dense_units=first_dense_units,\n",
    "                                                                   fc_layer_units=fc_layer_units,\n",
    "                                                                   debug=False)\n",
    "\n",
    "    cnn_model.compile(optimizer=tf.keras.optimizers.Adam(), loss='mean_squared_error', metrics=['mean_squared_error'])\n",
    "    cnn_model.load_weights(model_path)\n",
    "\n",
    "    return cnn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b37c63e3899463c3",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-22T17:47:58.319801700Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "cnn_model = load_model(model_path,\n",
    "                       bn=False,\n",
    "                       first_dense_units=512,\n",
    "                       fc_layer_units=[2048, 1024],\n",
    "                       lr=[5e-6, 2.5e-4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff946e884de8c907",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdeecc3cb9c1628d",
   "metadata": {},
   "source": [
    "### Load meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f005b84773badc02",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-22T17:47:58.335452900Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_directory, header=0, delimiter='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc437a1d9d36452",
   "metadata": {},
   "source": [
    "### Load images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90c33fbc-8b7e-46f7-b9a2-ee35274fd49f",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-22T17:47:58.335452900Z"
    }
   },
   "outputs": [],
   "source": [
    "def relative_path_to_absolute(row, right_eye=True):\n",
    "    if right_eye is True:\n",
    "        return f'{base_path}/{row[\"Participant\"]}/{row[\"Case\"]}/{normalised_directory}/{row[\"Right_eye_normalized\"]}'\n",
    "    else:\n",
    "        return f'{base_path}/{row[\"Participant\"]}/{row[\"Case\"]}/{normalised_directory}/{row[\"Left_eye_normalized\"]}'\n",
    "\n",
    "\n",
    "df_not_null = df.loc[df['Right_eye_normalized'].notnull(), :]\n",
    "right_eyes = df_not_null.apply(lambda row: relative_path_to_absolute(row, right_eye=True), axis=1)\n",
    "left_eyes = df_not_null.apply(lambda row: relative_path_to_absolute(row, right_eye=False), axis=1)\n",
    "\n",
    "\n",
    "def read_img(right, left):\n",
    "    images, _ = read_images_separate(right, left, None, efficientnet=True)\n",
    "    return images,\n",
    "\n",
    "\n",
    "ds_normalized = tf.data.Dataset.from_tensor_slices((right_eyes, left_eyes))\n",
    "ds_normalized = ds_normalized \\\n",
    "    .map(lambda right_eye_img, left_eye_img: read_img(right_eye_img, left_eye_img), num_parallel_calls=tf.data.AUTOTUNE) \\\n",
    "    .batch(32) \\\n",
    "    .cache() \\\n",
    "    .prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe0a1aa15f947685",
   "metadata": {},
   "source": [
    "### Execute prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b66e8336-67cf-4f25-b2c2-d010be09d55b",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-22T17:47:58.335452900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 28s 133ms/step\n"
     ]
    }
   ],
   "source": [
    "ds_normalized_predicted = cnn_model.predict(ds_normalized, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a00c5939a719d958",
   "metadata": {},
   "source": [
    "### Add predicted coordinates to meta dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12d87966-28c2-4627-9e24-0fbe0e5d7590",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-22T17:47:58.341800700Z"
    }
   },
   "outputs": [],
   "source": [
    "# Add to partial dataframe\n",
    "ds_normalized_predicted = ds_normalized_predicted.transpose()\n",
    "df_not_null['Rage-Net_X'] = np.multiply(ds_normalized_predicted[0], 1920)\n",
    "df_not_null['Rage-Net_Y'] = np.multiply(ds_normalized_predicted[1], 1080)\n",
    "\n",
    "columns_to_drop = ['Rage-Net_X', 'Rage-Net_Y']\n",
    "\n",
    "# Drop columns so there will be no duplicates after merge\n",
    "df = df.drop(columns_to_drop, axis=1, errors='ignore')\n",
    "\n",
    "# Add to whole dataframe\n",
    "df = pd.merge(df, df_not_null[['Right_eye_normalized', 'Rage-Net_X', 'Rage-Net_Y']],\n",
    "              on='Right_eye_normalized', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c69daa0-1c07-4dc4-b541-da5110cf8293",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-22T17:47:58.341800700Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Participant</th>\n",
       "      <th>Recording</th>\n",
       "      <th>Case</th>\n",
       "      <th>Stimul</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Fixation_X</th>\n",
       "      <th>Fixation_Y</th>\n",
       "      <th>File</th>\n",
       "      <th>Right_eye_normalized</th>\n",
       "      <th>Left_eye_normalized</th>\n",
       "      <th>Rage-Net_X</th>\n",
       "      <th>Rage-Net_Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P2</td>\n",
       "      <td>Recording5</td>\n",
       "      <td>case_1</td>\n",
       "      <td>Top center</td>\n",
       "      <td>192650117</td>\n",
       "      <td>955.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>0.jpg</td>\n",
       "      <td>0_right_eye.jpg</td>\n",
       "      <td>0_left_eye.jpg</td>\n",
       "      <td>992.763062</td>\n",
       "      <td>187.248215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P2</td>\n",
       "      <td>Recording5</td>\n",
       "      <td>case_1</td>\n",
       "      <td>Bottom left</td>\n",
       "      <td>194186638</td>\n",
       "      <td>151.0</td>\n",
       "      <td>972.0</td>\n",
       "      <td>1.jpg</td>\n",
       "      <td>1_right_eye.jpg</td>\n",
       "      <td>1_left_eye.jpg</td>\n",
       "      <td>89.265305</td>\n",
       "      <td>973.636658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P2</td>\n",
       "      <td>Recording5</td>\n",
       "      <td>case_1</td>\n",
       "      <td>Top right</td>\n",
       "      <td>195679731</td>\n",
       "      <td>1748.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>2.jpg</td>\n",
       "      <td>2_right_eye.jpg</td>\n",
       "      <td>2_left_eye.jpg</td>\n",
       "      <td>1765.614014</td>\n",
       "      <td>188.490295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P2</td>\n",
       "      <td>Recording5</td>\n",
       "      <td>case_1</td>\n",
       "      <td>Bottom center</td>\n",
       "      <td>197266136</td>\n",
       "      <td>942.0</td>\n",
       "      <td>985.0</td>\n",
       "      <td>3.jpg</td>\n",
       "      <td>3_right_eye.jpg</td>\n",
       "      <td>3_left_eye.jpg</td>\n",
       "      <td>924.300232</td>\n",
       "      <td>977.150940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P2</td>\n",
       "      <td>Recording5</td>\n",
       "      <td>case_1</td>\n",
       "      <td>Bottom right</td>\n",
       "      <td>198975859</td>\n",
       "      <td>1713.0</td>\n",
       "      <td>977.0</td>\n",
       "      <td>4.jpg</td>\n",
       "      <td>4_right_eye.jpg</td>\n",
       "      <td>4_left_eye.jpg</td>\n",
       "      <td>1726.082520</td>\n",
       "      <td>1041.627808</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Participant   Recording    Case         Stimul  Timestamp  Fixation_X  \\\n",
       "0          P2  Recording5  case_1     Top center  192650117       955.0   \n",
       "1          P2  Recording5  case_1    Bottom left  194186638       151.0   \n",
       "2          P2  Recording5  case_1      Top right  195679731      1748.0   \n",
       "3          P2  Recording5  case_1  Bottom center  197266136       942.0   \n",
       "4          P2  Recording5  case_1   Bottom right  198975859      1713.0   \n",
       "\n",
       "   Fixation_Y   File Right_eye_normalized Left_eye_normalized   Rage-Net_X  \\\n",
       "0       142.0  0.jpg      0_right_eye.jpg      0_left_eye.jpg   992.763062   \n",
       "1       972.0  1.jpg      1_right_eye.jpg      1_left_eye.jpg    89.265305   \n",
       "2       180.0  2.jpg      2_right_eye.jpg      2_left_eye.jpg  1765.614014   \n",
       "3       985.0  3.jpg      3_right_eye.jpg      3_left_eye.jpg   924.300232   \n",
       "4       977.0  4.jpg      4_right_eye.jpg      4_left_eye.jpg  1726.082520   \n",
       "\n",
       "    Rage-Net_Y  \n",
       "0   187.248215  \n",
       "1   973.636658  \n",
       "2   188.490295  \n",
       "3   977.150940  \n",
       "4  1041.627808  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac809d546db4a4bf",
   "metadata": {},
   "source": [
    "### Save dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d681967-1a38-4309-93ee-c8f38bea3fc0",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-22T17:47:58.341800700Z"
    }
   },
   "outputs": [],
   "source": [
    "# Save dataframe\n",
    "df.to_csv(data_directory, sep='\\t', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
